program: run_final.py
metric:
  name: Test Metrics Dict/combined_score
  goal: maximize
method: random
parameters:
  lr:
    # value: 2e-4
    distribution: q_log_uniform_values
    min: 1e-6
    max: 4e-6
    # min: 1e-4
    # max: 1e-2
    q: 1e-8
  eps:
    distribution: q_log_uniform_values
    min: 1e-10
    max: 1e-5
    q: 1e-10
    # value: 1e-7
  beta1:
    # value: 0.9
    distribution: q_log_uniform_values
    min: 0.85
    max: 0.95
    q: 1e-3
  beta2:
    # value: 0.999
    distribution: q_log_uniform_values
    min: 0.997
    max: 0.9995
    q: 1e-6
  entropy_loss_coeff:
    # values: [0.0, 0.75]
    value: 0.0
    # distribution: q_log_uniform_values
    # min: 0.001
    # max: 0.8
    # q: 1e-6
  # warmup_steps:
  #   value: 90
    # values: [0, 90, 180]
  epochs:
    value: 10
    # values: [5]
    # weights: [0.5, 0.4, 0.1]
  gamma:
    # value: 0.812
    distribution: q_log_uniform_values
    # distribution: uniform
    min: 0.35
    max: 0.65
    q: 1e-5
  subjective_score_type:
    # value: 'DMOS'
    values: ['MOS', 'DMOS']
    # weights: [0.6, 0.4]
  real_scenes_only:
    value: 'False'
    # values: ['True', 'False']
  regression_type:
    value: 'linear'
    # values: ['linear', 'sqrt']
    # weights: [0.6, 0.2, 0.2]
  weight_lower_bound:
    value: 0
    # values: [0.0, 1e-7]
    # distribution: q_log_uniform_values
    # min: 1e-9
    # max: 1e-7
    # q: 1e-8
  alpha_beta_ratio:
    value: 2.0
    # distribution: uniform
    # min: 1.7
    # max: 2.2
  dists_weight_norm:
    value: 'relu'
    # values: ['project', 'relu', 'relu+w_sum_detach', 'project+w_sum_detach']
  detach_beta:
    value: 'False'
    # values: ['True', 'False']

  optimizer:
    value: 'adam'
    # values: ['adam', 'sadamw'] #: ['nadam', 'adam', 'sgd', 'sgd_momentum']
    # weights: [0.7, 0.3]

command:
- ${env}
- ${interpreter}
- ${program}
- ${args}