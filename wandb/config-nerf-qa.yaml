program: run_final.py
metric:
  name: Test Metrics Dict/combined_score
  goal: maximize

method: random
parameters:
  lr:
    # value: 2e-4
    distribution: q_log_uniform_values
    min: 1e-7
    max: 1e-1
    # min: 1e-4
    # max: 1e-2
    q: 1e-8
  eps:
    distribution: q_log_uniform_values
    min: 1e-10
    max: 1e-5
    q: 1e-10
    # value: 1e-7
  beta1:
    # value: 0.9
    distribution: q_log_uniform_values
    min: 0.8
    max: 0.999
    q: 1e-3
  beta2:
    # value: 0.999
    distribution: q_log_uniform_values
    min: 0.998
    max: 0.99999
    q: 1e-6
  entropy_loss_coeff:
    distribution: q_log_uniform_values
    min: 0.3
    max: 4.0
    q: 1e-6
  # warmup_steps:
  #   value: 90
    # values: [0, 90, 180]
  epochs:
    # value: 10
    values: [5, 10]
    # weights: [0.5, 0.4, 0.1]
  gamma:
    # value: 0.812
    distribution: q_log_uniform_values
    # distribution: uniform
    min: 0.70
    max: 0.95
    q: 1e-5
  subjective_score_type:
    value: 'DMOS'
    # values: ['MOS', 'DMOS']
    # weights: [0.6, 0.4]
  real_scenes_only:
    values: ['True', 'False']
  regression_type:
    values: ['linear', 'sqrt']
    # weights: [0.6, 0.2, 0.2]
  weight_lower_bound:
    distribution: q_log_uniform_values
    min: 1e-9
    max: 5e-4
    q: 1e-8
  alpha_beta_ratio:
    distribution: uniform
    min: 1.0
    max: 2.0
  dists_weight_norm:
    values: ['project', 'relu', 'relu+w_sum_detach', 'project+w_sum_detach']
  detach_beta:
    values: ['True', 'False']

  optimizer:
    value: 'adam'
    # values: ['adam', 'sadamw'] #: ['nadam', 'adam', 'sgd', 'sgd_momentum']
    # weights: [0.7, 0.3]

command:
- ${env}
- ${interpreter}
- ${program}
- ${args}